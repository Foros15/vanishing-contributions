[System-setup]
num_workers = 36
seed = 42

[Model]
model_name = quantized-vit-tiny
store_folder = models
load_model = 
vit_model = WinKawaks/vit-tiny-patch16-224

[Task]
dataset = cifar10
dataset_root = .

[Online RS-STE pruning]
prune_model = False
prune_ratio = 0.9
prune_granularity = layer
prune_lambda_w = 0.0
prune_vcon_epochs = 0

[Online STE quantization]
quantize_model = True
quantize_vcon_epochs = 0

[Low Rank Decomposition]
lrd_model = False
lrd_rank = 16
lrd_vcon_epochs = 0

[Batch and epochs]
batch_size = 128
batch_accumulation = 1
starting_epoch = 0
total_epochs = 60

[Learning rate scheduling]
learning_rate = 0.0001
lr_decay_factor = 1.0
lr_patience = 10000
lr_minimum = 1e-06
lr_warmup_epochs = 1
lr_warmup_start = 1e-05
lr_cosine_decay = True

[Regularizations]
weight_decay = 0
clipping_global_norm = False
wsatstd = 

[Dataugmentation]
use_cutmix_mixup = True
use_mixup_only = True
mixup_alpha = 1.0
use_autoaugment = False
use_randaugment = True

